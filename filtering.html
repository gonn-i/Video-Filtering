<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <title>Project #2 - Video Processing</title>
    <style>
      html,
      body {
        margin: 0; /* remove the default margin          */
        height: 100%; /* make the html,body fill the page   */
      }
      canvas {
        display: block; /* make the canvas act like a block   */
        width: 100%; /* make the canvas fill its container */
        height: 100%;
      }
      #start {
        position: fixed;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        display: flex;
        justify-content: center;
        align-items: center;
      }
      #start > div {
        font-size: 200px;
        cursor: pointer;
      }
    </style>
  </head>
  <body>
    <canvas id="webgpu-canvas"></canvas>
    <pre id="fps"></pre>
    <div id="start">
      <div>▶️</div>
    </div>
  </body>
  <script type="importmap">
    {
      "imports": {
        "lil-gui": "https://cdn.jsdelivr.net/npm/lil-gui@0.19.2/dist/lil-gui.esm.js",
        "wgpu-matrix": "https://wgpu-matrix.org/dist/3.x/wgpu-matrix.module.js"
      }
    }
  </script>

  <script type="module">
    import { mat4 } from 'wgpu-matrix'; /* 행렬 연산을 위한 라이브러리 임포트 */
    import { GUI } from 'lil-gui'; /* 사용자 인터페이스를 위한 GUI 임포트 */

    // 텍스처 및 쉐이더 바인딩과 위치 설정
    // bindings & locations can be assigned arbitrarily.
    const binding_copy_tex_in = 2;
    const binding_copy_tex_out = 4;
    const binding_texquad_tex_out = 2;
    const binding_texquad_sampler = 4;
    const binding_texquad_uniform = 3;
    const loc_position = 5;
    const loc_inter_stage_uv = 1;

    const workgroup_size = [8, 8]; /* 워크그룹 크기 설정 */

    /* 필터 없이 비디오 그대로 처리 */
    const FILTER_NONE = 'no filter';

    async function main() {
      const adapter = await navigator.gpu?.requestAdapter();
      const hasBGRA8unormStorage = adapter.features.has('bgra8unorm-storage');
      const device = await adapter?.requestDevice();
      if (!device) {
        fail('need a browser that supports WebGPU');
        return;
      }

      const canvas = document.querySelector('#webgpu-canvas');
      const context = canvas.getContext('webgpu');
      const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
      context.configure({
        device,
        format: presentationFormat,
      });

      // 비디오 처리 시 사용할 행렬 데이터를 위한 버퍼 생성
      // create a typedarray to hold the a 4x4 f32 matrix uniform in JavaScript
      const videoMatrix = new Float32Array(16 * 4);
      // create a buffer for the uniform values
      const videoUniformBuffer = device.createBuffer({
        label: 'uniforms for video',
        size: videoMatrix.byteLength,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST /* UNIFORM 데이터로 사용 */,
      });

      const renderPassDescriptor = {
        label: 'our basic canvas renderPass',
        colorAttachments: [
          {
            // view: <- to be filled out when we render
            clearValue: [0.3, 0.3, 0.3, 1] /* 배경색 설정 */,
            loadOp: 'clear',
            storeOp: 'store',
          },
        ],
      };

      function startPlayingAndWaitForVideo(video) {
        return new Promise((resolve, reject) => {
          video.addEventListener('error', reject);
          if ('requestVideoFrameCallback' in video) {
            video.requestVideoFrameCallback(resolve); /* 비디오가 재생될 때까지 대기 */
          } else {
            const timeWatcher = () => {
              if (video.currentTime > 0) {
                resolve(); /* 비디오가 재생되면 Promise resolve */
              } else {
                requestAnimationFrame(timeWatcher); /* 비디오의 현재 시간을 확인하며 대기 */
              }
            };
            timeWatcher();
          }
          video.play().catch(reject); /* 비디오를 재생 */
        });
      }

      function waitForClick() {
        return new Promise((resolve) => {
          window.addEventListener(
            'click',
            () => {
              /* 클릭 시 'start' 영역 숨김 */
              document.querySelector('#start').style.display = 'none';
              resolve();
            },
            { once: true }
          );
        });
      }
      const video = document.createElement('video'); /* 비디오 요소 생성 */
      video.muted = true;
      video.loop = true;
      video.preload = 'auto';
      //    video.src = 'pexels-kosmo-politeska-5750980 (1080p).mp4';
      video.src = 'pexels-kosmo-politeska-5750980 (360p).mp4'; /* 비디오 파일 경로 */
      await waitForClick(); /* 클릭 대기 */
      await startPlayingAndWaitForVideo(video); /* 비디오 재생 대기 */

      // 클릭하면 비디오가 재생/일시 정지 되도록 이벤트 설정
      canvas.addEventListener('click', () => {
        if (video.paused) {
          video.play();
        } else {
          video.pause();
        }
      });

      let modules = {};

      // 쉐이더 코드 정의 (비디오 텍스처를 그대로 출력하는 단순 복사 연산)
      // compute shader which simply copies the original video (stored in "textureIn")
      // to the target texture ("textureOut").
      // You should create similar shaders to apply various image filters.
      modules[FILTER_NONE] = device.createShaderModule({
        label: `${FILTER_NONE} shader`,
        code: `
            @group(0) @binding(${binding_copy_tex_in}) var textureIn: texture_external;
            @group(0) @binding(${binding_copy_tex_out}) var textureOut: texture_storage_2d<rgba8unorm, write>;
    
            @compute @workgroup_size(${workgroup_size[0]},${workgroup_size[1]}) fn main_comp(
                @builtin(global_invocation_id) id: vec3u
            ) {
                let uv = id.xy;

                var texel = textureLoad(textureIn, uv);
                textureStore(textureOut, uv, texel); /* 비디오 텍스처를 처리된 텍스처로 저장 */
            }
        `,
      });

      // 2D 쿼드 텍스처를 그리기 위한 쉐이더
      // The vertex & fragment shaders which draws a textured quad
      const moduleTexQuad = device.createShaderModule({
        label: 'textured quad shaders',
        code: `
            struct VertexInfo {
                @builtin(position) position: vec4f,
                @location(${loc_inter_stage_uv}) uv: vec2f
            };
            
            struct Uniforms {
                matrix: mat4x4f,
            };
            
            @group(0) @binding(${binding_texquad_uniform}) var<uniform> uni: Uniforms;
            
            @vertex fn vs(
                @location(${loc_position}) position: vec3f
            ) -> VertexInfo {
          
                var vertexOut: VertexInfo;
                vertexOut.position = uni.matrix * vec4f(position, 1.0); /* 위치 변환 */
                vertexOut.position = vec4f(vec3f(2,-2,0.0)*position, 1.0) + vec4f(-1,1,0,0);
                vertexOut.uv = position.xy; /* 텍스처 좌표 설정 */
                return vertexOut;
            }
            
            @group(0) @binding(${binding_texquad_sampler}) var ourSampler: sampler;
            @group(0) @binding(${binding_texquad_tex_out}) var ourTexture: texture_2d<f32>;
            
            @fragment fn fs(@location(${loc_inter_stage_uv}) uv: vec2f) -> @location(0) vec4f {
                return textureSampleBaseClampToEdge(
                    ourTexture,
                    ourSampler,
                    uv,
              );
            }
        `,
      });

      modules['grayscale'] = device.createShaderModule({
        label: 'grayscale shader',
        code: `
    @group(0) @binding(${binding_copy_tex_in}) var textureIn: texture_external;
    @group(0) @binding(${binding_copy_tex_out}) var textureOut: texture_storage_2d<rgba8unorm, write>;

    @compute @workgroup_size(${workgroup_size[0]},${workgroup_size[1]}) fn main_comp(
        @builtin(global_invocation_id) id: vec3u
    ) {
        let uv = id.xy;

        // Load the texel from the input texture
        var texel = textureLoad(textureIn, uv);

        // Calculate luminance using Rec. 709 luma coefficients
        let gray = 0.2126 * texel.r + 0.7152 * texel.g + 0.0722 * texel.b;
        textureStore(textureOut, uv, vec4f(gray, gray, gray, texel.a));
    }
  `,
      });

      modules['gaussian filter (7 x 7)'] = device.createShaderModule({
        label: 'Gaussian Blur Shader_1',
        code: `
          @group(0) @binding(${binding_copy_tex_in}) var textureIn: texture_external;
          // 입력 텍스처에 바인딩
          @group(0) @binding(${binding_copy_tex_out}) var textureOut: texture_storage_2d<rgba8unorm, write>;
          // 출력 텍스처에 바인딩

          const kernel: array<f32, 49> = array<f32, 49>(
              0.0003, 0.0021, 0.0106, 0.0275, 0.0452, 0.0275, 0.0106, // 커널 값 정의 (7x7 가우시안 필터)
              0.0021, 0.0125, 0.0619, 0.1605, 0.2644, 0.1605, 0.0619,
              0.0106, 0.0619, 0.2644, 0.6843, 1.0000, 0.6843, 0.2644,
              0.0275, 0.1605, 0.6843, 1.0000, 1.0000, 0.6843, 0.1605,
              0.0452, 0.2644, 1.0000, 1.0000, 0.6843, 0.2644, 0.0452,
              0.0275, 0.1605, 0.6843, 0.6843, 0.1605, 0.0275, 0.0106,
              0.0021, 0.0619, 0.2644, 0.6843, 0.1605, 0.0619, 0.0021
          );

            const kernel_radius= 1;

          @compute @workgroup_size(8, 8) 
          // 컴퓨트 셰이더 정의 및 워크그룹 크기 설정
          fn main_comp(
              @builtin(global_invocation_id) id: vec3u // 글로벌 스레드 ID
          ) {
              let uv = vec2<i32>(id.xy); // 현재 픽셀 좌표 가져오기
              var blurredColor: vec4f = vec4f(0.0, 0.0, 0.0, 0.0); // 블러링된 색상을 저장할 변수 초기화

              for (var i: i32 = -kernel_radius; i <= kernel_radius; i = i + 1) {
                  for (var j: i32 = -kernel_radius; j <= kernel_radius; j = j + 1) {
  
                      let neighborUV = uv + vec2<i32>(i, j);

                      // 텍스처 경계 체크 (텍스처 범위 외부 접근 방지)
                      if (neighborUV.x >= 0 && neighborUV.y >= 0) {
                          let texel = textureLoad(textureIn, neighborUV); // 이웃 픽셀의 색상 값 읽기
                          let weightIndex = (i + kernel_radius) * (2 * kernel_radius + 1) + (j + kernel_radius); // 커널의 현재 인덱스 계산
                          let weight = kernel[weightIndex]; // 커널 가중치 가져오기
                          blurredColor += texel * weight; // 가중치를 곱해 블러링된 색상에 누적
                      }
                  }
              }
              const brightness = 5.0; 
              textureStore(textureOut, uv, blurredColor * brightness); // 최종 블러링된 색상을 출력 텍스처에 저장
          }
          `,
      });

      modules['gaussian filter (7 x 7, slow)'] = device.createShaderModule({
        label: 'Gaussian Blur Shader',
        code: `
        // 바인딩된 텍스처들
        @group(0) @binding(${binding_copy_tex_in}) var textureIn: texture_external;
        @group(0) @binding(${binding_copy_tex_out}) var textureOut: texture_storage_2d<rgba8unorm, write>;
      
        const kernel: array<f32, 49> = array<f32, 49>(
            0.0003, 0.0021, 0.0106, 0.0275, 0.0452, 0.0275, 0.0106,
            0.0021, 0.0125, 0.0619, 0.1605, 0.2644, 0.1605, 0.0619,
            0.0125, 0.0619, 0.2644, 0.6843, 1.0000, 0.6843, 0.2644,
            0.0619, 0.1605, 0.6843, 1.0000, 1.0000, 0.6843, 0.1605,
            0.0275, 0.0452, 0.2644, 1.0000, 1.0000, 0.2644, 0.0452,
            0.0275, 0.0106, 0.1605, 0.6843, 1.0000, 0.6843, 0.1605,
            0.0106, 0.0021, 0.0619, 0.2644, 0.6843, 0.2644, 0.0619
        );
      
        // 커널 반경을 i32로 정의
        const kernel_radius= 1;
      
        // 커널 값들의 합을 구하고 이를 이용해 정규화
        const kernel_sum = 1; // 커널의 합이 1이어야 함
        const normalized_kernel: array<f32, 49> = array<f32, 49>(
            // 커널 값들을 정규화
            0.0003 / kernel_sum, 0.0021 / kernel_sum, 0.0106 / kernel_sum, 0.0275 / kernel_sum, 0.0452 / kernel_sum, 0.0275 / kernel_sum, 0.0106 / kernel_sum,
            0.0021 / kernel_sum, 0.0125 / kernel_sum, 0.0619 / kernel_sum, 0.1605 / kernel_sum, 0.2644 / kernel_sum, 0.1605 / kernel_sum, 0.0619 / kernel_sum,
            0.0125 / kernel_sum, 0.0619 / kernel_sum, 0.2644 / kernel_sum, 0.6843 / kernel_sum, 1.0000 / kernel_sum, 0.6843 / kernel_sum, 0.2644 / kernel_sum,
            0.0619 / kernel_sum, 0.1605 / kernel_sum, 0.6843 / kernel_sum, 1.0000 / kernel_sum, 1.0000 / kernel_sum, 0.6843 / kernel_sum, 0.1605 / kernel_sum,
            0.0275 / kernel_sum, 0.0452 / kernel_sum, 0.2644 / kernel_sum, 1.0000 / kernel_sum, 1.0000 / kernel_sum, 0.2644 / kernel_sum, 0.0452 / kernel_sum,
            0.0275 / kernel_sum, 0.0106 / kernel_sum, 0.1605 / kernel_sum, 0.6843 / kernel_sum, 1.0000 / kernel_sum, 0.6843 / kernel_sum, 0.1605 / kernel_sum,
            0.0106 / kernel_sum, 0.0021 / kernel_sum, 0.0619 / kernel_sum, 0.2644 / kernel_sum, 0.6843 / kernel_sum, 0.2644 / kernel_sum, 0.0619 / kernel_sum
        );
      
            @compute @workgroup_size(${workgroup_size[0]}, ${workgroup_size[1]}) fn main_comp(
            @builtin(global_invocation_id) id: vec3u
        ) {
            // uv는 i32 타입으로 선언하여 offset과 덧셈 연산이 가능하도록 처리
            var uv: vec2<i32> = vec2<i32>(id.xy);

            // 블러링된 컬러를 저장할 변수
            var blurredColor: vec4f = vec4f(0.0, 0.0, 0.0, 0.0);

            // 커널 인덱스를 계산할 변수 (이중 루프를 사용하여 각 커널 값에 대해 가중치를 적용)
            var kernelIndex: i32 = 3;

            // 커널을 순회하며 각 texel을 가중합
            for (var i: i32 = -kernel_radius; i <= kernel_radius; i = i + 1) {
                for (var j: i32 = -kernel_radius; j <= kernel_radius; j = j + 1) {
                    // 커널에 해당하는 UV 좌표 계산
                    let offset = vec2<i32>(i, j);  // offset을 i32로 선언
                    let texel_uv = uv + offset;

                    // 텍스처의 범위를 벗어나지 않도록 UV 좌표 조정 (클램프)
                    let clamped_uv = clamp(texel_uv, vec2<i32>(0, 0), vec2<i32>(textureDimensions(textureIn).xy - 1));

                    // 텍스처에서 색상 값 로드
                    let texel = textureLoad(textureIn, clamped_uv);

                    // 커널 값에 따라 가중치를 적용하고 블러 색상 계산
                    let weight = normalized_kernel[u32(kernelIndex)];
                    blurredColor = blurredColor + texel * weight;

                    // 커널 인덱스 증가
                    kernelIndex = kernelIndex + 1;
                }
            }

         // 최종적으로 계산된 블러 색상을 클램프하여 저장
          let clampedColor = clamp(blurredColor, vec4f(0.0, 0.0, 0.0, 0.0), vec4f(1.0, 1.0, 1.0, 1.0));
            textureStore(textureOut, id.xy, clampedColor);
            }
      
      `,
      });

      let pipelines = {};
      let filters = [];

      // 다양한 필터 처리 파이프라인 생성
      for (let filter in modules) {
        pipelines[filter] = device.createComputePipeline({
          label: `${filter} pipeline`,
          layout: 'auto',
          compute: {
            module: modules[filter],
          },
        });
        filters.push(filter);
      }

      // lil-gui 필터 선택 UI 생성
      let menu = { filter: FILTER_NONE };

      const gui = new GUI();

      gui.add(menu, 'filter', filters);

      const pipelineTexQuad = device.createRenderPipeline({
        label: 'textured quad pipeline',
        layout: 'auto',
        vertex: {
          module: moduleTexQuad,
          buffers: [
            {
              arrayStride: 8,
              attributes: [
                {
                  format: 'float32x2',
                  offset: 0,
                  shaderLocation: loc_position,
                },
              ],
            },
          ],
        },
        fragment: {
          module: moduleTexQuad,
          targets: [{ format: presentationFormat }],
        },
      });

      const sampler = device.createSampler({
        magFilter: 'linear',
        minFilter: 'linear',
      });

      const textureOut = device.createTexture({
        label: 'processed video texture',
        format: 'rgba8unorm',
        size: [video.videoWidth, video.videoHeight],
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.STORAGE_BINDING,
      });

      const bindGroupTexQuad = device.createBindGroup({
        layout: pipelineTexQuad.getBindGroupLayout(0),
        entries: [
          { binding: binding_texquad_sampler, resource: sampler },
          { binding: binding_texquad_tex_out, resource: textureOut.createView() },
          { binding: binding_texquad_uniform, resource: { buffer: videoUniformBuffer } },
        ],
      });

      const num_workgroups = [
        Math.floor((video.videoWidth + workgroup_size[0] - 1) / workgroup_size[0]),
        Math.floor((video.videoHeight + workgroup_size[1] - 1) / workgroup_size[1]),
      ];

      // vertex attributes for two triangles of a quad
      const vertices = new Float32Array([
        // 1st triangle
        0, 0, 1, 0, 1, 1,
        // 2nd triangle
        0, 0, 1, 1, 0, 1,
      ]);
      const vertexBuffer = device.createBuffer({
        label: 'quad vertices',
        size: vertices.byteLength,
        usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(vertexBuffer, 0, vertices);

      function render() {
        const encoder = device.createCommandEncoder({ label: 'video processing encoder' });

        // 1st pass: image processing using a compute pipeline
        {
          const textureIn = device.importExternalTexture({ source: video });

          // We have to create a bindgroup at every frame since we're using an "external texture."
          // See https://webgpufundamentals.org/webgpu/lessons/webgpu-textures-external-video.html
          const bindGroup = device.createBindGroup({
            layout: pipelines[menu.filter].getBindGroupLayout(0),
            entries: [
              { binding: binding_copy_tex_in, resource: textureIn },
              { binding: binding_copy_tex_out, resource: textureOut.createView() },
            ],
          });

          const pass = encoder.beginComputePass();

          pass.setPipeline(pipelines[menu.filter]);
          pass.setBindGroup(0, bindGroup);
          pass.dispatchWorkgroups(video.videoWidth, video.videoHeight);

          pass.end();
        }

        {
          const canvasTexture = context.getCurrentTexture().createView();
          renderPassDescriptor.colorAttachments[0].view = canvasTexture;

          const pass = encoder.beginRenderPass(renderPassDescriptor);

          // Create a matrix according to th current aspct ratio of the canvas
          // to keep the aspect ratio of the video.
          const canvasAspect = canvas.clientWidth / canvas.clientHeight;
          const videoAspect = video.videoWidth / video.videoHeight;
          const scale =
            canvasAspect > videoAspect ? [1, canvasAspect / videoAspect, 1] : [videoAspect / canvasAspect, 1, 1];

          const matrix = mat4.identity(videoMatrix);
          mat4.scale(matrix, scale, matrix);
          mat4.translate(matrix, [-1, 1, 0], matrix);
          mat4.scale(matrix, [2, -2, 1], matrix);

          device.queue.writeBuffer(videoUniformBuffer, 0, videoMatrix);

          pass.setPipeline(pipelineTexQuad);
          pass.setBindGroup(0, bindGroupTexQuad);
          pass.setVertexBuffer(0, vertexBuffer);
          pass.draw(6); // call our vertex shader 6 times
          pass.end();
        }

        const commandBuffer = encoder.finish();
        device.queue.submit([commandBuffer]);

        requestAnimationFrame(render);
      }

      requestAnimationFrame(render);

      const observer = new ResizeObserver((entries) => {
        for (const entry of entries) {
          const canvas = entry.target;
          const width = entry.contentBoxSize[0].inlineSize;
          const height = entry.contentBoxSize[0].blockSize;
          canvas.width = Math.max(1, Math.min(width, device.limits.maxTextureDimension2D));
          canvas.height = Math.max(1, Math.min(height, device.limits.maxTextureDimension2D));
        }
      });
      observer.observe(canvas);
    }

    function fail(msg) {
      alert(msg);
    }

    main();
  </script>
</html>
